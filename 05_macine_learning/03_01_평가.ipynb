{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf0e57fa-0d68-4d83-bc45-71d70b0afe11",
   "metadata": {},
   "source": [
    "# 평가\n",
    "\n",
    "## 분류\n",
    "예측 값에 대한 결과 값이 맞냐 아니냐 대해 명확하게 구분하려 함.\n",
    "\n",
    "## 회귀\n",
    "예측 값과 결과의 차이가 가 작으면 정확하다 판단.\n",
    "\n",
    "## 정확도\n",
    "전체 데이터에서 예측해서 맞춘 결과의 퍼센트\n",
    "\n",
    "- 오류\n",
    ": 이진 분류로 데이터의 불균형이 심한 데이터를 학습하면 엄청난 정확도를 나타내지만 다른 데이터로 예측할 때 정확도가 매우 오차가 커진다.\n",
    "따라서 정확도만 보고 모델을 검증하면 안된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "79d890f9-af54-4864-bd83-0de2c3c3d52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습은 안하고 예측만 하게 만들어봄\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "# 클래스 이름 붙여줘야 한다. 클래스 명은 보통 첫 단어부터 첫 글자를 대문자로 사용.\n",
    "# 이 클래스는 상속 받을 때 다중 클래스 상속 가능하다.\n",
    "class MyDummyClassifier(BaseEstimator):\n",
    "    # 함수에서 fit 정의할 때는 파라미터로 self라고 정의를 하지만 \n",
    "    # 대중적으로 self라고 적어줌 self 안에 들어간 주소 수정하기 빡세니까 수정 안하는게 좋음.\n",
    "    # 나중에 어차피 활용 안됨.\n",
    "    def fit(self,X,y=None):\n",
    "        pass \n",
    "    \n",
    "    # 여기선 fit에 아무것도 없어서 학습을 안한다.\n",
    "    def predict(self,X):\n",
    "        # 행은 데이터 건수 만큼, 열은 결과값만 받으면 되니까 1\n",
    "        pred = np.zeros((X.shape[0],1))\n",
    "        for i in range(X.shape[0]):\n",
    "            # 들어오는 x값의 성별이 해당 인덱스로 가도록 설정\n",
    "            if X['Sex'].iloc[i] == 1:\n",
    "                pred[i] = 0\n",
    "            else:\n",
    "                pred[i] = 1\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4deb6ba-e07f-4d89-8ad3-dc8176a1eec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['female' 'male']\n",
      "['A' 'B' 'C' 'D' 'E' 'F' 'G' 'N' 'T']\n",
      "['C' 'N' 'Q' 'S']\n"
     ]
    }
   ],
   "source": [
    "# 데이터 수정할 내용 바꿔주고\n",
    "def fillna(df):\n",
    "    df['Age'].fillna(df['Age'].mean(),inplace=True)\n",
    "    df['Cabin'].fillna('N',inplace=True)\n",
    "    df['Embarked'].fillna('N',inplace=True)\n",
    "    df['Fare'].fillna(0,inplace=True)\n",
    "    return df\n",
    "\n",
    "def drop_features(df):\n",
    "    df.drop(columns=['PassengerId','Name','Ticket'],inplace=True)\n",
    "    return df\n",
    "\n",
    "def format_features(df):\n",
    "    #레이블 인코더는 함수 안에 같이 넣어주는 것이 좋다.\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    \n",
    "    df['Cabin'] = df['Cabin'].str[:1]\n",
    "    features=['Sex','Cabin','Embarked']\n",
    "    for feature in features:\n",
    "        le = LabelEncoder()\n",
    "        df[feature] = le.fit_transform(df[feature])\n",
    "        # 데이터 몇 개 안되면 그냥 숫자값에 뭐가 있는지 보고 작업하면 좋다.\n",
    "        print(le.classes_)\n",
    "    return df\n",
    "\n",
    "def transform_features(df):\n",
    "    df = fillna(df)\n",
    "    df = drop_features(df)\n",
    "    df = format_features(df)\n",
    "    return df\n",
    "\n",
    "df = pd.read_csv('titanic.csv')\n",
    "y = df['Survived']\n",
    "X = df.drop(columns=['Survived'])\n",
    "X = transform_features(X)\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ead65389-66b2-4616-a466-fa240ac82b0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8324022346368715"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myclf = MyDummyClassifier()\n",
    "myclf.fit(X_train,y_train)\n",
    "pred = myclf.predict(X_test)\n",
    "accuracy_score(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18f47d-1d92-465d-a65b-eaef4327dd52",
   "metadata": {},
   "source": [
    "# 오차행렬\n",
    "정확도가 높아도 실제로 정확하지 않을 수 있어서 오차행렬로 신뢰도를 확인해 볼 수 있다.\n",
    "1이라고 예측을 할 때, 오차 행렬에서의 오차 데이터를 보고 정확도의 신뢰도를 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d04b3548-26c9-4309-a43e-207f0317060f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e76b8dfe-31b3-4c6d-8023-66b3bb504a97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[103,  15],\n",
       "       [ 15,  46]], dtype=int64)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31163b-5c1c-4c90-bc29-b6460f58849f",
   "metadata": {},
   "source": [
    "### 정확도\n",
    "예측 결과와 실제 값이 동일한 건수 / 전체 데이터 수\n",
    "\n",
    "## 정밀도와 재현율\n",
    "혼동행렬에서 나온다.\n",
    "이 수치는 동시에 올라갈 수가 없다. 어느 하나가 높아지면 나머지 하나가 낮아진다.\n",
    "\n",
    "### 정밀도(Precision) = 양성 예측도\n",
    "예측 값 기준으로\n",
    "내가 1이라고 예측해서 실제로 1이라고 맞춘 비율\n",
    "ex. 스팸 메일 거르다가 내 정상 메일까지 걸러버리면 안되기 때문에 정밀도가 더 중요.\n",
    "\n",
    "### 재현율(Recall) = 민감도 = TPR\n",
    "실제 값 기준으로\n",
    "실제 1인 결과들에서 1이라고 예측에 성공한 비율\n",
    "ex. 암환자 구분 모델에서 암환자 놓치면 안되기 때문에 재현율이 더 중요.\n",
    "\n",
    "*** 농산물 판별 프로젝트는 재현율이 더 높아야 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fce8fe-055f-4fd6-b8e6-a13e04dd8e3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
